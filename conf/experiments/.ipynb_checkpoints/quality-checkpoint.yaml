defaults:
  - ../config
  - _self_

model:
  name: t5-small

# NEW: ReduceLROnPlateau scheduler configuration (conservative for quality)
scheduler:
  patience: 5          # More patience for quality convergence
  factor: 0.7          # Conservative reduction for quality
  threshold: 0.0005    # Lower threshold for quality improvements
  min_lr: 1e-8         # Very low minimum for fine quality tuning

vignette_training:
  epochs: 16  # More epochs for quality focus
  batch_size: 2  # Smaller batch for more precise updates
  eval_batch_size: 4
  gradient_accumulation_steps: 4  # Higher accumulation to maintain effective batch size
  learning_rate: 1.2e-4  # Lower learning rate for quality
  warmup_steps: 100  # Extended warmup for stability
  weight_decay: 0.02  # Higher regularization for quality
  eval_steps: 15  # More frequent evaluation
  save_steps: 30
  early_stopping_patience: 8  # More patience for quality convergence
  label_smoothing_factor: 0.12  # Moderate smoothing

optimization:
  fp16: true
  dataloader_pin_memory: false
  gradient_checkpointing: true

# PHASE 1 ENHANCEMENT: Quality-focused generation with longer outputs
generation:
  max_length: 420           # Slightly higher than others for quality
  min_length: 65            # Higher minimum for quality
  num_beams: 8              # Highest beam search for quality
  early_stopping: false     # Let it generate full content
  do_sample: false
  repetition_penalty: 1.12  # Lower penalty for medical repetition
  length_penalty: 1.5       # Strong preference for longer outputs
  no_repeat_ngram_size: 2   # Allow some repetition for medical terms
  diversity_penalty: 0.1    # NEW - Encourage diverse vocabulary

paths:
  output_dir: ./experiments/quality
  logs_dir: ./experiments/quality/logs
